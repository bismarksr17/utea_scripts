{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50ffbee-12f5-4b24-8ca3-ac0394c8b08c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ProxyTypes' from 'httpx._types' (C:\\Users\\bismarksr\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\_types.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01masyncio\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhttpx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msqlalchemy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_engine, text\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __description__, __title__, __version__\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delete, get, head, options, patch, post, put, request, stream\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_auth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Auth, BasicAuth, DigestAuth, NetRCAuth\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m USE_CLIENT_DEFAULT, AsyncClient, Client\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\_api.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_TIMEOUT_CONFIG\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Response\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     AuthTypes,\n\u001b[0;32m      9\u001b[0m     CertTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     VerifyTypes,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m     24\u001b[0m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     25\u001b[0m     url: URLTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\_client.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_transports\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdefault\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AsyncHTTPTransport, HTTPTransport\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_transports\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwsgi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WSGITransport\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     AsyncByteStream,\n\u001b[0;32m     34\u001b[0m     AuthTypes,\n\u001b[0;32m     35\u001b[0m     CertTypes,\n\u001b[0;32m     36\u001b[0m     CookieTypes,\n\u001b[0;32m     37\u001b[0m     HeaderTypes,\n\u001b[0;32m     38\u001b[0m     ProxiesTypes,\n\u001b[0;32m     39\u001b[0m     QueryParamTypes,\n\u001b[0;32m     40\u001b[0m     RequestContent,\n\u001b[0;32m     41\u001b[0m     RequestData,\n\u001b[0;32m     42\u001b[0m     RequestExtensions,\n\u001b[0;32m     43\u001b[0m     RequestFiles,\n\u001b[0;32m     44\u001b[0m     SyncByteStream,\n\u001b[0;32m     45\u001b[0m     TimeoutTypes,\n\u001b[0;32m     46\u001b[0m     URLTypes,\n\u001b[0;32m     47\u001b[0m     VerifyTypes,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_urls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m URL, QueryParams\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     Timer,\n\u001b[0;32m     52\u001b[0m     URLPattern,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m     same_origin,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\_transports\\default.py:56\u001b[0m\n\u001b[0;32m     53\u001b[0m T \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mTypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTPTransport\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m A \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mTypeVar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, bound\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsyncHTTPTransport\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m SOCKET_OPTION \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mUnion[\n\u001b[0;32m     57\u001b[0m     typing\u001b[38;5;241m.\u001b[39mTuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m     58\u001b[0m     typing\u001b[38;5;241m.\u001b[39mTuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, typing\u001b[38;5;241m.\u001b[39mUnion[\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m]],\n\u001b[0;32m     59\u001b[0m     typing\u001b[38;5;241m.\u001b[39mTuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m     60\u001b[0m ]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_httpcore_exceptions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ProxyTypes' from 'httpx._types' (C:\\Users\\bismarksr\\anaconda3\\envs\\utea_reportes\\lib\\site-packages\\httpx\\_types.py)"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import httpx\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, text\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "ENGINE = create_engine(\"postgresql+psycopg://postgres:A123456*@localhost:5433/utea\")\n",
    "VIAJES = 500\n",
    "PROMEDIO_LLEGADAS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b014e6ad-4867-4e08-a2f1-875312c1cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ Función para consultar API con manejo de errores\n",
    "async def extraer_datos(endpoint, fecha_ini, fecha_fin):\n",
    "    url = f\"http://10.1.0.103:9080/Utea/{endpoint}\"\n",
    "    params = {\n",
    "        \"pStrFecIni\": fecha_ini,\n",
    "        \"pStrFecFin\": fecha_fin,\n",
    "    }\n",
    "    timeout = httpx.Timeout(10.0)\n",
    "    try:\n",
    "        async with httpx.AsyncClient(timeout=timeout) as client:\n",
    "            response = await client.get(url, params=params)\n",
    "            if response.status_code == 200:\n",
    "                now = datetime.now()\n",
    "                formatted_now = now.strftime('%d/%m/%Y %H:%M:%S')\n",
    "                print(formatted_now + \" - GET: \" + endpoint)\n",
    "                return response.json()\n",
    "            else:\n",
    "                print(f\"⚠️ Error {response.status_code} en {endpoint}\")\n",
    "                return None\n",
    "    except httpx.RequestError as e:\n",
    "        print(f\"❌ Error de conexión con {endpoint}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a06d868-d478-48b5-8a01-16332bacdf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_hora_madrugada():\n",
    "    ahora = datetime.now().time()\n",
    "    return (ahora.hour >= 0 and ahora.hour < 7)\n",
    "\n",
    "def calcular_horas_espera(df_tcb):\n",
    "    df = df_tcb.copy()\n",
    "    # elimina todos los registro sin datos de fechaDocum y HoraDocum\n",
    "    #df = df.dropna(subset=['canero'])\n",
    "    df = df[df['dateDocum'] != '0000-00-00']\n",
    "    #extrae la hora para FECHA DE INICIO\n",
    "    df['horaDocum'] = df['horaDocum'].str.split('T').str[1]\n",
    "    # concatena fecha y hora\n",
    "    df['fecha_inicio'] = df['dateDocum'] + ' ' + df['horaDocum']\n",
    "    # convierte la columna a tipo datetime\n",
    "    df['fecha_inicio'] = pd.to_datetime(df['fecha_inicio'])\n",
    "    #extraer la hora para FECHA DE FIN\n",
    "    df['startTime'] = df['startTime'].str.split('T').str[1]\n",
    "    # concatena fecha y hora\n",
    "    df['fecha_fin'] = df['startDate'] + ' ' + df['startTime']\n",
    "    # convierte la columna a tipo datetime\n",
    "    df['fecha_fin'] = pd.to_datetime(df['fecha_fin'])\n",
    "    #calcula la diferencia\n",
    "    df['espera'] = (df['fecha_fin'] - df['fecha_inicio']).dt.total_seconds() / 3600\n",
    "    #retorn la media\n",
    "    return df['espera'].mean()\n",
    "\n",
    "def definir_trapiche(df):\n",
    "    # extrae la hora\n",
    "    df['solo_hora'] = df['hora'].str.split('T').str[1]\n",
    "    # concatena fecha y hora\n",
    "    df['fecha_hora'] = df['fecha'] + ' ' + df['solo_hora']\n",
    "    # convierte la columna a tipo datetime\n",
    "    df['fecha_hora'] = pd.to_datetime(df['fecha_hora'])\n",
    "    # obtiene la fecha y hora actual\n",
    "    hora_actual = datetime.now()\n",
    "    # calcula una hora antes\n",
    "    una_hora_antes = hora_actual - timedelta(hours=1)\n",
    "    # filtra los resgistros de la ultima hora\n",
    "    df_ultima_hora = df[(df['fecha_hora'] >= una_hora_antes) & (df['fecha_hora'] <= hora_actual)]\n",
    "    trapiches = list(set(df_ultima_hora['trapiche']))\n",
    "    trapiches = [int(i) for i in trapiches]\n",
    "    if len(trapiches) == 0:\n",
    "        return 0\n",
    "    elif 1 in trapiches and 2 in trapiches:\n",
    "        return 3\n",
    "    elif 1 in trapiches:\n",
    "        return 1\n",
    "    elif 2 in trapiches:\n",
    "        return 2\n",
    "    return 0\n",
    "\n",
    "def get_horarios():\n",
    "    try:\n",
    "        df = pd.read_sql(\"SELECT * FROM datos_iag.horarios\", ENGINE)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error al consultar PostgreSQL:\", e)\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fe91a2f-6ad8-418e-bfd4-1f662500143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2️⃣ Simulación de función de cálculo\n",
    "def calcular_datos(df_playa, df_trafCamBalanza, df_molienda):\n",
    "\n",
    "    df_horarios = get_horarios()\n",
    "    if df_horarios.empty:\n",
    "        return {}\n",
    "    df_molienda['hora2'] = df_molienda['hora2'].astype(int)\n",
    "    df_res_molienda = pd.merge(df_molienda, df_horarios[['Hora', 'Orden_Hora']], left_on='hora2', right_on='Hora', how='left')\n",
    "    \n",
    "    #cantidad de paquetes\n",
    "    #cantidad de caña disponible\n",
    "    filtro = df_playa[(df_playa['status'] == 'PL') | (df_playa['status'] == 'IN')]\n",
    "    cantidad_paquetes = filtro['cantPqt'].sum()\n",
    "    cana_disponible = cantidad_paquetes * 45\n",
    "    \n",
    "    #promedio lleganda pq\n",
    "    df_playa['dateCupo'] = pd.to_datetime(df_playa['dateCupo'])\n",
    "    fecha_actual = pd.Timestamp('today').normalize()\n",
    "    df_actual = df_playa[(df_playa['dateCupo'] == fecha_actual) & (df_playa['status'] != 'SL')].copy()\n",
    "    df_actual['Hora_Entera'] = df_actual['horaDocum'].str[11:13].astype(int)\n",
    "    max_hora_ent = df_actual['Hora_Entera'].max() - 3\n",
    "    filtered_df = df_actual[df_actual['Hora_Entera'] >= max_hora_ent]\n",
    "    sum_cant_pqt = filtered_df['cantPqt'].sum()\n",
    "    promedio_llegada_pq = sum_cant_pqt / 3\n",
    "    \n",
    "    #trapiches\n",
    "    # trapiche1    210 tn/ha    15 paquetes\n",
    "    # trapiche2    690 tn/ha    49 paquetes\n",
    "    \n",
    "    #horas molienda\n",
    "    horas_molienda_t1 = cantidad_paquetes / 5\n",
    "    horas_molienda_t2 = cantidad_paquetes / 15\n",
    "    horas_molienda_total = cantidad_paquetes / (5 + 15)\n",
    "    \n",
    "    #total paquetes resto dia\n",
    "    total_paquetes_resto_dia_t1 = promedio_llegada_pq * horas_molienda_t1\n",
    "    total_paquetes_resto_dia_t2 = promedio_llegada_pq * horas_molienda_t2\n",
    "    total_paquetes_resto_dia_total = promedio_llegada_pq * horas_molienda_total\n",
    "    \n",
    "    #toneladas\n",
    "    toneladas = df_molienda['netWeight'].sum() / 1000\n",
    "    \n",
    "    #planificacion actual\n",
    "    planificacion_actual_t1 = df_res_molienda['Orden_Hora'].max() * 210\n",
    "    planificacion_actual_t2 = df_res_molienda['Orden_Hora'].max() * 690\n",
    "    planificacion_actual_total = df_res_molienda['Orden_Hora'].max() * (210 + 690)\n",
    "    \n",
    "    #diferencia actual\n",
    "    diferencia_actual_t1 = toneladas - planificacion_actual_t1\n",
    "    diferencia_actual_t2 = toneladas - planificacion_actual_t2\n",
    "    diferencia_actual_total = toneladas - planificacion_actual_total\n",
    "    \n",
    "    #orden hora\n",
    "    orden_hora = 24 - df_res_molienda['Orden_Hora'].max()\n",
    "    \n",
    "    #toneladas promedio\n",
    "    toneladas_prom = (df_molienda['netWeight'].sum() / 1000) / (24 - orden_hora)\n",
    "\n",
    "    #total horas\n",
    "    total_horas_t1 = total_paquetes_resto_dia_t1 / (5) + horas_molienda_t1\n",
    "    total_horas_t2 = total_paquetes_resto_dia_t2 / (15) + horas_molienda_t2\n",
    "    total_horas_total = (total_paquetes_resto_dia_total / (5 + 15)) + horas_molienda_total\n",
    "\n",
    "    #molienda segun promedio\n",
    "    molienda_s_promedio = (toneladas_prom * orden_hora) + toneladas\n",
    "\n",
    "    #molienda segun estimado\n",
    "    molienda_s_estimado_t1 = toneladas + orden_hora * 210\n",
    "    molienda_s_estimado_t2 = toneladas + orden_hora * 690\n",
    "    molienda_s_estimado_total = toneladas + orden_hora * (210 + 690)\n",
    "\n",
    "    #tiempo espera\n",
    "    espera =  calcular_horas_espera(df_trafCamBalanza)\n",
    "    trapiches = definir_trapiche(df_molienda)\n",
    "\n",
    "    trapiches_estado = \"01 y 02\"\n",
    "    viajes_disponibles = float(cantidad_paquetes)\n",
    "    toneladas_aprox = float(cana_disponible)\n",
    "    promedio_llegada_viajes = float(promedio_llegada_pq)\n",
    "    viajes_estimados = float(total_paquetes_resto_dia_total)\n",
    "    total_horas_abastecimiento = float(total_horas_total)\n",
    "    tiempo_espera = float(espera)\n",
    "    molienda_actual = float(toneladas)\n",
    "    planificacion_actual = float(planificacion_actual_total)\n",
    "    diferencia_actual = float(diferencia_actual_total)\n",
    "    promedio_horario = float(toneladas_prom)\n",
    "    molienda_segun_promedio = float(molienda_s_promedio)\n",
    "    molienda_segun_estimacion = float(molienda_s_estimado_total)\n",
    "    \n",
    "    if trapiches == 0:\n",
    "        trapiches_estado = \"Detenidos\"\n",
    "        viajes_estimados = 0\n",
    "        total_horas_abastecimiento = 0\n",
    "        planificacion_actual = 0\n",
    "        diferencia_actual = 0\n",
    "        molienda_segun_estimacion = 0\n",
    "    elif trapiches == 1:\n",
    "        trapiches_estado = \"solo 01\"\n",
    "        viajes_estimados = float(total_paquetes_resto_dia_t1)\n",
    "        total_horas_abastecimiento = float(total_horas_t1)\n",
    "        planificacion_actual = float(planificacion_actual_t1)\n",
    "        diferencia_actual = float(diferencia_actual_t1)\n",
    "        molienda_segun_estimacion = float(molienda_s_estimado_t1)\n",
    "    elif trapiches == 2:\n",
    "        trapiches_estado = \"solo 02\"\n",
    "        viajes_estimados = float(total_paquetes_resto_dia_t2)\n",
    "        total_horas_abastecimiento = float(total_horas_t2)\n",
    "        planificacion_actual = float(planificacion_actual_t2)\n",
    "        diferencia_actual = float(diferencia_actual_t2)\n",
    "        molienda_segun_estimacion = float(molienda_s_estimado_t2)\n",
    "    elif trapiches == 3:\n",
    "        None\n",
    "        #ya esta definido al inicio\n",
    "    \n",
    "    dict_datos = {\n",
    "        \"trapiches_estado\": \"01 y 02\",\n",
    "        \"viajes_disponibles\": float(cantidad_paquetes),\n",
    "        \"toneladas_aprox\": float(cana_disponible),\n",
    "        \"promedio_llegada_viajes\": float(promedio_llegada_pq),\n",
    "        \"viajes_estimados\": float(total_paquetes_resto_dia_total),\n",
    "        \"total_horas_abastecimiento\": float(total_horas_total),\n",
    "        \"tiempo_espera\": float(espera),\n",
    "        \"molienda_actual\": float(toneladas),\n",
    "        \"planificacion_actual\": float(planificacion_actual_total),\n",
    "        \"diferencia_actual\": float(diferencia_actual_total),\n",
    "        \"promedio_horario\": float(toneladas_prom),\n",
    "        \"molienda_segun_promedio\": float(molienda_s_promedio),\n",
    "        \"molienda_segun_estimacion\": float(molienda_s_estimado_total)\n",
    "    }\n",
    "    return dict_datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16a7aa02-0eb1-4de8-b16e-f94eb0c2d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3️⃣ Función para guardar en PostgreSQL\n",
    "def actualizar_reporte(datos):\n",
    "    try:\n",
    "        set_clause = \", \".join([f\"{key} = :{key}\" for key in datos.keys()])\n",
    "        datos[\"id\"] = 1  # condición WHERE id = 1\n",
    "        query = text(f\"UPDATE datos_iag.reporte SET {set_clause} WHERE id = :id\")\n",
    "\n",
    "        with ENGINE.begin() as conn:\n",
    "            conn.execute(query, datos)\n",
    "            print(\"✅ Registro actualizado correctamente (SQLAlchemy)\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error al actualizar con SQLAlchemy:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d16840a2-533b-4f90-ab14-d6ca2640fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4️⃣ Función principal asíncrona\n",
    "async def ciclo_principal():\n",
    "    while True:\n",
    "        hoy = datetime.now().strftime('%Y-%m-%d')\n",
    "        ayer = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "\n",
    "        # Hacer todas las peticiones en paralelo\n",
    "        tareas = [\n",
    "            extraer_datos(\"ReportePlaya\", ayer, hoy),\n",
    "            extraer_datos(\"TrafCamBalanza\", ayer, hoy),\n",
    "            extraer_datos(\"Molienda\", ayer if es_hora_madrugada() else hoy, ayer if es_hora_madrugada() else hoy)\n",
    "        ]\n",
    "        ReportePlaya, TrafCamBalanza, Molienda = await asyncio.gather(*tareas)\n",
    "        # Validar que todas tengan datos antes de calcular\n",
    "        if all([ReportePlaya, TrafCamBalanza, Molienda]):\n",
    "            resultado = calcular_datos(\n",
    "                pd.DataFrame(ReportePlaya), \n",
    "                pd.DataFrame(TrafCamBalanza), \n",
    "                pd.DataFrame(Molienda)\n",
    "            )\n",
    "            now = datetime.now()\n",
    "            formatted_now = now.strftime('%H:%M:%S')\n",
    "            resultado[\"hora\"] = formatted_now\n",
    "            \n",
    "            actualizar_reporte(resultado)\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            print(\"⚠️ No se pudieron obtener todos los datos. Se omite el cálculo.\")\n",
    "        await asyncio.sleep(300)  # espera 5 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e5e2d-58ff-4735-a2ed-12ede7cd6295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5️⃣ Ejecutar\n",
    "if __name__ == \"__main__\":\n",
    "    await ciclo_principal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebe35b-d673-43a4-81cb-b4ce7c605f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4678f2d-a361-4718-92a1-945960487c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_alerta(datos):\n",
    "    \n",
    "    viajes_disponibles = resultado['viajes_disponibles']\n",
    "    \n",
    "    if viajes_disponibles > 200:\n",
    "        if viajes <= 200:\n",
    "            viajes = viajes_disponibles\n",
    "            return mensaje\n",
    "    elif viajes_disponibles > 120:\n",
    "        if viajes <= 120:\n",
    "            viajes = viajes_disponibles\n",
    "            return mensaje\n",
    "    elif viajes_disponibles >= 20 and viajes_disponibles <= 120:\n",
    "        viajes = viajes_disponibles\n",
    "        return False\n",
    "    elif viajes_disponibles < 20:\n",
    "        if viajes >= 20:\n",
    "            viajes = viajes_disponibles\n",
    "            return mensaje\n",
    "    elif promedio_llegada_pq >= 8:\n",
    "        if promedio_llegadas < 8:\n",
    "            promedio_llegadas = promedio_llegada_pq\n",
    "            return mensaje\n",
    "        else:\n",
    "            promedio_llegadas = promedio_llegada_pq\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e4327d-73ff-45b8-8b13-8cc8294f62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = {\n",
    "    'trapiches_estado': '01 y 02', \n",
    "    'viajes_disponibles': 190.0, \n",
    "    'toneladas_aprox': 8550.0, \n",
    "    'promedio_llegada_viajes': 26.666666666666668, \n",
    "    'viajes_estimados': 253.33333333333334, \n",
    "    'total_horas_abastecimiento': 22.166666666666668, \n",
    "    'tiempo_espera': 8.053206152433425, \n",
    "    'molienda_actual': 3921.89, \n",
    "    'planificacion_actual': 4500.0, \n",
    "    'diferencia_actual': -578.1100000000001, \n",
    "    'promedio_horario': 784.3779999999999, \n",
    "    'molienda_segun_promedio': 18825.072, \n",
    "    'molienda_segun_estimacion': 21021.89, \n",
    "    'hora': '10:57:08'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e45d49-4d89-439d-95f0-e2ac9f7f396b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado['viajes_disponibles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b17522-208f-4969-a478-2e0c84586523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d629c7-c067-4ebb-ab7d-6877dc4a9c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc32cd-b5ea-4759-b75e-03e8fa41fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c5b42-9b1c-4416-b551-d4a0f8e967a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe0eb7-8918-4dde-8817-5f2a171dedda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
