{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d26f64e-c1fb-424d-bb27-d4ab069c2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopandas.tools import sjoin\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, MultiPoint\n",
    "from shapely import wkb\n",
    "import simplekml\n",
    "\n",
    "from utilities_amigocloud import AmigocloudFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc905f8-33ed-4173-b267-2332df0f91e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import RUTA_UNIDAD_ONE_DRIVE\n",
    "from config import RUTA_LOCAL_ONE_DRIVE\n",
    "from config import API_AMIGOCLOUD_TOKEN_ADM\n",
    "from config import POSTGRES_UTEA\n",
    "\n",
    "RUTA_COMPLETA = os.path.join(RUTA_UNIDAD_ONE_DRIVE, RUTA_LOCAL_ONE_DRIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ca72f7-550e-4557-8a31-52ed67dfaea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obtener_engine():\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://{POSTGRES_UTEA['USER']}:{POSTGRES_UTEA['PASSWORD']}@{POSTGRES_UTEA['HOST']}:{POSTGRES_UTEA['PORT']}/{POSTGRES_UTEA['DATABASE']}\"\n",
    "    )\n",
    "\n",
    "def obtener_planificacion_no_procesado():\n",
    "    engine = obtener_engine()\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "            SELECT id_os, geom, cod_ca, nom_ca, obs, procesado\n",
    "            FROM drones_control_bio.planificacion_ctrl_bio\n",
    "            WHERE procesado=false;\n",
    "        \"\"\"\n",
    "        gdf = gpd.read_postgis(query, engine, geom_col='geom')\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en la consulta: {e}\")\n",
    "        return gpd.GeoDataFrame()\n",
    "    return None\n",
    "\n",
    "def obtener_parte_diario_por_id_os(id_os):\n",
    "    engine = obtener_engine()\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "            SELECT * FROM drones_control_bio.parte_diario_ctrl_bio where os = {id_os}\n",
    "        \"\"\"\n",
    "        gdf = gpd.read_postgis(query, engine, geom_col='geom')\n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en la consulta: {e}\")\n",
    "        return gpd.GeoDataFrame()\n",
    "    return None\n",
    "\n",
    "def filtrar_os_y_quitar_caracteres(gdf, ors):\n",
    "    # filtrar la semana de interes\n",
    "    gdf_puntos_select = gdf[gdf['id_os'] == ors]\n",
    "    gdf_puntos_sem = gdf_puntos_select.copy()\n",
    "    #quita caracteres especiales\n",
    "    gdf_puntos_sem['nom_ca'] = gdf_puntos_sem['nom_ca'].str.replace(r'[\\r\\n\\t]', '', regex=True)\n",
    "    return gdf_puntos_sem\n",
    "\n",
    "def marcar_como_procesado(id_os):\n",
    "    engine = obtener_engine()  # tu función que crea el engine\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            query = text(\"\"\"\n",
    "                UPDATE drones_control_bio.planificacion_ctrl_bio\n",
    "                SET procesado = true\n",
    "                WHERE id_os = :id_os\n",
    "            \"\"\")\n",
    "            conn.execute(query, {\"id_os\": id_os})\n",
    "            print(f\"✔️ id_os {id_os} marcado como procesado.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al actualizar: {e}\")\n",
    "    return None\n",
    "\n",
    "def crear_puntos_individuales(gdf):\n",
    "    # Crear una lista para almacenar los nuevos registros de puntos individuales\n",
    "    point_records = []\n",
    "    # Iterar sobre cada registro en el GeoDataFrame original\n",
    "    for idx, row in gdf.iterrows():\n",
    "        multipoint_geom = row.geom\n",
    "        # Verificar si la geometría es de tipo multipunto\n",
    "        if isinstance(multipoint_geom, MultiPoint):\n",
    "            for point in multipoint_geom.geoms:\n",
    "                # Crear un nuevo registro para cada punto individual\n",
    "                new_record = row.copy()\n",
    "                new_record.geometry = point\n",
    "                point_records.append(new_record)\n",
    "        else:\n",
    "            # Si la geometría ya es un punto, simplemente añadir el registro original\n",
    "            point_records.append(row)\n",
    "    \n",
    "    # Crear un nuevo GeoDataFrame con los registros de puntos individuales\n",
    "    puntos_indi = gpd.GeoDataFrame(point_records, geometry='geom', crs=gdf.crs)\n",
    "    return puntos_indi\n",
    "\n",
    "def definir_lotes_solicitud(gdf_puntos_indi):\n",
    "    # Crear un GeoDataFrame vacío para almacenar los puntos que no intersectan con ningún polígono de siembra\n",
    "    puntos_indi_solicitado = gdf_puntos_indi[~gdf_puntos_indi.geometry.apply(lambda point: any(gdf_siembras.contains(point)))]\n",
    "    # identifoca los lotes que se intersectan\n",
    "    gdf_lotes_cat = gpd.sjoin(gdf_cat, puntos_indi_solicitado, how='inner', predicate='intersects')\n",
    "    # filtra los lotes intersectados en la capa original\n",
    "    poligonos_intersect_cat = gdf_cat.loc[gdf_cat.index.isin(gdf_lotes_cat.index)]\n",
    "    # copy\n",
    "    poligonos_intersect_cat = poligonos_intersect_cat.copy()\n",
    "    poligonos_intersect_cat = poligonos_intersect_cat[['unidad_01', 'unidad_02', 'unidad_03', 'unidad_04', 'unidad_05', 'area', 'soca', 'zona', 'geometry']]\n",
    "    # Cambiar el nombre de la columna 'old_name' a 'new_name'\n",
    "    poligonos_intersect_cat.rename(columns={'zona': 'inst'}, inplace=True)\n",
    "    # CAMBIAR NOMBRE DATOS DE UNIDAD_03 Y UNDIAD_04 DE LOTES SOLICITADOS A LO INDICADO EN LOS PUNTOS\n",
    "    # Iterar sobre cada punto y encontrar el polígono que intersecta\n",
    "    for idx, point in puntos_indi_solicitado.iterrows():\n",
    "        point_geom = point.geom\n",
    "        matching_polygons = poligonos_intersect_cat[poligonos_intersect_cat.intersects(point_geom)]\n",
    "    \n",
    "        # Actualizar los campos de los polígonos que intersectan con los valores del punto\n",
    "        for poly_idx in matching_polygons.index:\n",
    "            poligonos_intersect_cat.at[poly_idx, 'unidad_03'] = point['cod_ca']\n",
    "            poligonos_intersect_cat.at[poly_idx, 'unidad_04'] = point['nom_ca']\n",
    "    # agrega los campos faltantes\n",
    "    poligonos_intersect_cat['fecha_ini'] = ''\n",
    "    poligonos_intersect_cat['origen'] = 'SOLICITUD'\n",
    "    poligonos_intersect_cat['dias'] = 0\n",
    "    poligonos_intersect_cat['fecha'] = ''\n",
    "    poligonos_intersect_cat['os'] = ors\n",
    "    return poligonos_intersect_cat\n",
    "\n",
    "def definir_lotes_siembra(gdf_puntos_indi):\n",
    "    # SELECCIONAR LOS LOTES DE SIEMBRAS\n",
    "    # identifoca los lotes que se intersectan\n",
    "    gdf_lotes_siem = gpd.sjoin(gdf_siembras, gdf_puntos_indi, how='inner', predicate='intersects')\n",
    "    # filtra los lotes intersectados en la capa original\n",
    "    poligonos_intersect_siem = gdf_siembras.loc[gdf_siembras.index.isin(gdf_lotes_siem.index)]\n",
    "    # copy\n",
    "    poligonos_intersect_siem = poligonos_intersect_siem.copy()\n",
    "    # agregar campo de semana_planificacion\n",
    "    poligonos_intersect_siem['os'] = ors\n",
    "    # crea el campo soca, y coloca 0 o 1 dependiendo del origen\n",
    "    poligonos_intersect_siem['soca'] = poligonos_intersect_siem['origen'].apply(lambda x: 1 if 'SIEMBRA 2023' in x else 0)\n",
    "    # ordena los campos\n",
    "    poligonos_intersect_siem = poligonos_intersect_siem[['unidad_01', 'unidad_02', 'unidad_03', 'unidad_04', 'unidad_05', 'area',\n",
    "           'fecha_ini', 'origen', 'dias', 'fecha', 'prioridad', 'inst', 'geometry', 'os', 'soca']]\n",
    "    return poligonos_intersect_siem\n",
    "\n",
    "def agregar_campos_faltantes(gdf_plan):\n",
    "    gdf_plan['producto'] = ''\n",
    "    gdf_plan['dosis'] = 0.0\n",
    "    gdf_plan['id_labor'] = ''\n",
    "    gdf_plan['fecha'] = ''\n",
    "    gdf_plan['semana'] = 0\n",
    "    gdf_plan['num_lib'] = 0\n",
    "    gdf_plan['hora_ini'] = ''\n",
    "    gdf_plan['hora_fin'] = ''\n",
    "    gdf_plan['temp'] = 0\n",
    "    gdf_plan['viento'] = 0\n",
    "    gdf_plan['humedad'] = 0\n",
    "    gdf_plan['cod_dron'] = ''\n",
    "    gdf_plan['piloto_1'] = ''\n",
    "    gdf_plan['piloto_2'] = ''\n",
    "    gdf_plan['obs'] = ''\n",
    "    gdf_plan['id_log'] = 0\n",
    "    return gdf_plan\n",
    "\n",
    "def convertir_a_multipolygon(geometry):\n",
    "    if isinstance(geometry, Polygon):\n",
    "        return MultiPolygon([geometry])\n",
    "    return geometry\n",
    "\n",
    "def convertir_a_wkb(polygon):\n",
    "    wkb_data = wkb.dumps(polygon, hex=True)\n",
    "    return wkb_data\n",
    "\n",
    "def cargar_a_amigocloud(gdf):\n",
    "    # repreyectar a WGS84\n",
    "    gdf_pla_gral = gdf.to_crs(epsg=4326)\n",
    "    # convertir poligonos a multipoligonos\n",
    "    gdf_pla_gral['geom'] = gdf_pla_gral['geom'].apply(convertir_a_multipolygon)\n",
    "    \n",
    "    gdf_pla_gral['unidad_01'] = gdf_pla_gral['unidad_01'].astype(int)\n",
    "    gdf_pla_gral['unidad_03'] = gdf_pla_gral['unidad_03'].astype(int)\n",
    "    gdf_pla_gral['dias'] = gdf_pla_gral['dias'].astype(int)\n",
    "    gdf_pla_gral['os'] = gdf_pla_gral['os'].astype(int)\n",
    "    gdf_pla_gral['soca'] = gdf_pla_gral['soca'].astype(int)\n",
    "    gdf_pla_gral['id'] = gdf_pla_gral['id'].astype(int)\n",
    "    gdf_pla_gral['inst'] = gdf_pla_gral['inst'].astype(int)\n",
    "    \n",
    "    # recorrer el gdf de lotes y cargarlo a amigocloud\n",
    "    id_proyecto = 33457\n",
    "    for index, row in gdf_pla_gral.iterrows():\n",
    "        wkb_hex = convertir_a_wkb(row['geom'])\n",
    "        insert_sql = f\"\"\"\n",
    "            INSERT INTO dataset_345601 (id, unidad_01, unidad_02, unidad_03, unidad_04, unidad_05, area, origen, dias, os, geometry)\n",
    "            VALUES ({row['id']}, {row['unidad_01']}, '{row['unidad_02']}', {row['unidad_03']}, '{row['unidad_04']}', '{row['unidad_05']}', {row['area']}, '{row['origen']}', '{row['dias']}', '{row['os']}', ST_SetSRID(ST_GeomFromWKB('\\\\x{wkb_hex}'), 4326));\n",
    "            \"\"\"\n",
    "        query_sql = {'query': insert_sql}\n",
    "        resultado_post = amigocloud.ejecutar_query_sql(id_proyecto, insert_sql, 'post')\n",
    "    return None\n",
    "        \n",
    "def crear_kmls(gdf_lotes):\n",
    "    lista_cods = list(set(gdf_lotes['unidad_01']))\n",
    "    for i in lista_cods:\n",
    "        prop = plan_os[plan_os['unidad_01'] == i]\n",
    "        prop_wgs = prop.to_crs(epsg=4326)\n",
    "        output_folder = PATH_KML + '\\\\' + str(i)\n",
    "        print(output_folder)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        # Recorrer el GeoDataFrame\n",
    "        for idx, row in prop_wgs.iterrows():\n",
    "            # Crear un nuevo documento KML\n",
    "            kml_doc = simplekml.Kml()\n",
    "            # Obtener el polígono y el nombre\n",
    "            polygon = row['geom']\n",
    "            name = row['unidad_05']\n",
    "            # Convertir el polígono en una lista de coordenadas\n",
    "            if polygon.geom_type == \"Polygon\":\n",
    "                coords = [(x, y) for x, y in zip(*polygon.exterior.xy)]\n",
    "            elif polygon.geom_type == \"MultiPolygon\":\n",
    "            # puedes iterar si quieres más de uno, aquí tomamos el primero\n",
    "                first_poly = list(polygon.geoms)[0]\n",
    "                coords = [(x, y) for x, y in zip(*first_poly.exterior.xy)]\n",
    "            else:\n",
    "                print(f\"❌ Geometría no compatible: {polygon.geom_type}\")\n",
    "                continue  # salta este registro\n",
    "            # Añadir el polígono al documento KML\n",
    "            pol = kml_doc.newpolygon(name=name, outerboundaryis=coords)\n",
    "            # Guardar el archivo KML\n",
    "            file_name = f\"{name}.kml\"\n",
    "            output_path = os.path.join(output_folder, file_name)\n",
    "            kml_doc.save(output_path)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d102d776-8a85-4ab2-bd4f-e915ae3d48b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utilities_amigocloud.AmigocloudFunctions at 0x2c26bb8c0a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amigocloud = AmigocloudFunctions(token=API_AMIGOCLOUD_TOKEN_ADM)\n",
    "amigocloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c420e1d-e2fc-453f-b471-ffac204a192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer los dos shps de siembra y puntos de planificacion\n",
    "PATH_SIEMBRA = RUTA_UNIDAD_ONE_DRIVE + r'\\Ingenio Azucarero Guabira S.A\\UTEA - SEMANAL - EQUIPO AVIACION UTEA\\Trichogramma\\2025\\SHP\\SIEMBRAS.shp'\n",
    "PATH_CAT = RUTA_UNIDAD_ONE_DRIVE + r'\\Ingenio Azucarero Guabira S.A\\UTEA - SEMANAL - EQUIPO AVIACION UTEA\\Trichogramma\\2025\\SHP\\CATASTRO_S13.shp'\n",
    "PATH_KML = RUTA_UNIDAD_ONE_DRIVE + r'\\Ingenio Azucarero Guabira S.A\\UTEA - SEMANAL - EQUIPO AVIACION UTEA\\Trichogramma\\2025\\KML_PLAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b0afe-f0a8-465a-bfbc-08fb3ecc23a4",
   "metadata": {},
   "source": [
    "# ACTUALIZAR SHP PLANIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4e9ac23-1a2f-4609-9bdd-6b9f06e37005",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_siembras = gpd.read_file(PATH_SIEMBRA)\n",
    "gdf_cat = gpd.read_file(PATH_CAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc1fd95f-d690-4c6c-8f6c-ade5b12a4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_puntos = obtener_planificacion_no_procesado()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a4bfac-c39b-4e85-b843-2a7cb306dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_os</th>\n",
       "      <th>geom</th>\n",
       "      <th>cod_ca</th>\n",
       "      <th>nom_ca</th>\n",
       "      <th>obs</th>\n",
       "      <th>procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>MULTIPOINT (473348.814 8095790.855, 473155.440...</td>\n",
       "      <td>515</td>\n",
       "      <td>AGUILERA OLGA RIVERO VDA DE</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_os                                               geom  cod_ca  \\\n",
       "0     12  MULTIPOINT (473348.814 8095790.855, 473155.440...     515   \n",
       "\n",
       "                        nom_ca   obs  procesado  \n",
       "0  AGUILERA OLGA RIVERO VDA DE  None      False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e53c3c-7a4a-499d-8284-f3ec67fd40a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ id_os 12 marcado como procesado.\n"
     ]
    }
   ],
   "source": [
    "for i, row in gdf_puntos.iterrows():\n",
    "    ors = row['id_os']\n",
    "    puntos = filtrar_os_y_quitar_caracteres(gdf_puntos, ors)\n",
    "    multipoint_gdf = puntos.copy()\n",
    "    puntos_individuales = crear_puntos_individuales(multipoint_gdf)\n",
    "    \n",
    "    lotes_solicidud = definir_lotes_solicitud(puntos_individuales)\n",
    "    lotes_siembra = definir_lotes_siembra(puntos_individuales)\n",
    "    \n",
    "    # verificar si algun dataframe esta vacio\n",
    "    dfs = [df for df in [lotes_solicidud, lotes_siembra] if not df.empty]\n",
    "    # concatena los dfs no vacios\n",
    "    concat_plan = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    \n",
    "    plan = agregar_campos_faltantes(concat_plan)\n",
    "    #RECALCULAR EL AREA\n",
    "    plan['area'] = plan.geometry.area / 10000\n",
    "    \n",
    "    plan.rename(columns={'geometry': 'geom'}, inplace=True)\n",
    "    plan = plan.set_geometry(\"geom\")\n",
    "    plan['unidad_01'] = plan['unidad_01'].astype(int)\n",
    "    plan['unidad_03'] = plan['unidad_03'].astype(int)\n",
    "    plan['dias'] = plan['dias'].astype(int)\n",
    "    plan['os'] = plan['os'].astype(int)\n",
    "    plan['soca'] = plan['soca'].astype(int)\n",
    "    plan['inst'] = plan['inst'].astype(int)\n",
    "    plan.to_postgis(\"parte_diario_ctrl_bio\", obtener_engine(), schema=\"drones_control_bio\", if_exists=\"append\")\n",
    "    \n",
    "    # CARGAR LOTES A AMIGOCLOUD\n",
    "    plan_os = obtener_parte_diario_por_id_os(ors)\n",
    "    cargar_a_amigocloud(plan_os)\n",
    "    \n",
    "    marcar_como_procesado(ors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c229ae6-e3f4-4af8-8310-774664c9b916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c911b-0e63-44fa-89df-2c17ab5463f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc0b97-1798-4308-9694-3f9fca8ac079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3ceab-2847-4019-85b7-e88028b0f496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
